{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4be5d807",
   "metadata": {},
   "source": [
    "# Quickstart: Agentic retrieval in Azure AI Search\n",
    "\n",
    "Use this notebook to get started with [agentic retrieval](https://learn.microsoft.com/azure/search/search-agentic-retrieval-concept) in Azure AI Search, which integrates conversation history and large language models (LLMs) on Azure OpenAI to plan, retrieve, and synthesize complex queries.\n",
    "\n",
    "Steps in this notebook include:\n",
    "\n",
    "+ Creating an `earth_at_night` search index.\n",
    "\n",
    "+ Loading the index with documents from a GitHub URL.\n",
    "\n",
    "+ Creating an `earth-search-agent` in Azure AI Search that points to an LLM for query planning.\n",
    "\n",
    "+ Using the agent to fetch and rank relevant information from the index.\n",
    "\n",
    "+ Generating answers using the Azure OpenAI client.\n",
    "\n",
    "This notebook provides a high-level demonstration of agentic retrieval. For more detailed guidance, see [Quickstart: Run agentic retrieval in Azure AI Search](https://learn.microsoft.com/azure/search/search-get-started-agentic-retrieval)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6712b97d",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "+ An [Azure AI Search service](https://learn.microsoft.com/azure/search/search-create-service-portal) on the Basic tier or higher with [semantic ranker enabled](https://learn.microsoft.com/azure/search/semantic-how-to-enable-disable).\n",
    "\n",
    "+ An [Azure OpenAI resource](https://learn.microsoft.com/azure/ai-services/openai/how-to/create-resource).\n",
    "\n",
    "+ A [supported model](https://learn.microsoft.com/azure/search/search-agentic-retrieval-how-to-create#supported-models) deployed to your Azure OpenAI resource. This notebook uses `gpt-4.1-mini`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5fbd46",
   "metadata": {},
   "source": [
    "## Configure access\n",
    "\n",
    "This notebook assumes authentication and authorization using Microsoft Entra ID and role assignments. It also assumes that you run the code from your local device.\n",
    "\n",
    "To configure role-based access:\n",
    "\n",
    "1. Sign in to the [Azure portal](https://portal.azure.com).\n",
    "\n",
    "1. [Enable role-based access](https://learn.microsoft.com/azure/search/search-security-enable-roles) on your Azure AI Search service.\n",
    "\n",
    "1. [Create a system-assigned managed identity](https://learn.microsoft.com/azure/search/search-howto-managed-identities-data-sources#create-a-system-managed-identity) on your Azure AI Search service.\n",
    "\n",
    "1. On your Azure AI Search service, [assign the following roles](https://learn.microsoft.com/azure/search/search-security-rbac#how-to-assign-roles-in-the-azure-portal) to yourself.\n",
    "\n",
    "   + **Search Service Contributor**\n",
    "\n",
    "   + **Search Index Data Contributor**\n",
    "\n",
    "   + **Search Index Data Reader**\n",
    "\n",
    "1. On your Azure OpenAI resource, assign **Cognitive Services User** to the managed identity of your search service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733bf308",
   "metadata": {},
   "source": [
    "## Set up connections\n",
    "\n",
    "The `sample.env` file contains environment variables for connections to Azure AI Search and Azure OpenAI. Agentic retrieval requires these connections for document retrieval, query planning, query execution, and answer generation.\n",
    "\n",
    "To set up connections:\n",
    "\n",
    "1. Sign in to the [Azure portal](https://portal.azure.com).\n",
    "\n",
    "2. Retrieve the endpoints for both Azure AI Search and Azure OpenAI.\n",
    "\n",
    "3. Save the `sample.env` file as `.env` on your local device.\n",
    "\n",
    "4. Update the `.env` file with the retrieved endpoints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a54a0f",
   "metadata": {},
   "source": [
    "## Create a virtual environment\n",
    "\n",
    "The `requirements.txt` file contains the dependencies for this notebook. You can install these dependencies in isolation using a virtual environment.\n",
    "\n",
    "To create a virtual environment:\n",
    "\n",
    "1. In Visual Studio Code, open the folder that contains `quickstart.ipynb`.\n",
    "\n",
    "1. Press **Ctrl**+**Shift**+**P** to open the command palette.\n",
    "\n",
    "1. Search for **Python: Create Environment**, and then select **Venv**.\n",
    "\n",
    "1. Select a Python installation. We tested this notebook on Python 3.13.\n",
    "\n",
    "1. Select `requirements.txt` for the dependencies.\n",
    "\n",
    "Creating the virtual environment can take several minutes. When the environment is ready, proceed to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0714a968",
   "metadata": {},
   "source": [
    "## Install packages and load connections\n",
    "\n",
    "This step installs the packages for this notebook and establishes connections to Azure AI Search and Azure OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "041e5d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df3a118",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True) # Take environment variables from .env.\n",
    "\n",
    "# The following variables from your .env file are used in this notebook\n",
    "answer_model = os.getenv(\"ANSWER_MODEL\", \"gpt-4o\")\n",
    "endpoint = os.environ[\"AZURE_SEARCH_ENDPOINT\"]\n",
    "credential = DefaultAzureCredential()\n",
    "token_provider = get_bearer_token_provider(credential, \"https://search.azure.com/.default\")\n",
    "index_name = os.getenv(\"AZURE_SEARCH_INDEX\", \"earth_at_night\")\n",
    "azure_openai_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "azure_openai_gpt_deployment = os.getenv(\"AZURE_OPENAI_GPT_DEPLOYMENT\", \"gpt-4o\")\n",
    "azure_openai_gpt_model = os.getenv(\"AZURE_OPENAI_GPT_MODEL\", \"gpt-4o\")\n",
    "azure_openai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2025-03-01-preview\")\n",
    "azure_openai_embedding_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\", \"text-embedding-3-large\")\n",
    "azure_openai_embedding_model = os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\", \"text-embedding-3-large\")\n",
    "agent_name = os.getenv(\"AZURE_SEARCH_AGENT_NAME\", \"earth-search-agent\")\n",
    "api_version = \"2025-05-01-Preview\"\n",
    "\n",
    "print(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e8a088",
   "metadata": {},
   "source": [
    "## Create an index in Azure AI Search\n",
    "\n",
    "This step creates a search index that contains plain text and vector content. You can use an existing index, but it must meet the criteria for [agentic retrieval workloads](https://learn.microsoft.com/azure/search/search-agentic-retrieval-how-to-index). The primary schema requirement is a semantic configuration with a `default_configuration_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee48bec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import SearchIndex, SearchField, VectorSearch, VectorSearchProfile, HnswAlgorithmConfiguration, AzureOpenAIVectorizer, AzureOpenAIVectorizerParameters, SemanticSearch, SemanticConfiguration, SemanticPrioritizedFields, SemanticField\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "\n",
    "index = SearchIndex(\n",
    "    name=index_name,\n",
    "    fields=[\n",
    "        SearchField(name=\"id\", type=\"Edm.String\", key=True, filterable=True, sortable=True, facetable=True),\n",
    "        SearchField(name=\"page_chunk\", type=\"Edm.String\", filterable=False, sortable=False, facetable=False),\n",
    "        SearchField(name=\"page_embedding_text_3_large\", type=\"Collection(Edm.Single)\", stored=False, vector_search_dimensions=3072, vector_search_profile_name=\"hnsw_text_3_large\"),\n",
    "        SearchField(name=\"page_number\", type=\"Edm.Int32\", filterable=True, sortable=True, facetable=True)\n",
    "    ],\n",
    "    vector_search=VectorSearch(\n",
    "        profiles=[VectorSearchProfile(name=\"hnsw_text_3_large\", algorithm_configuration_name=\"alg\", vectorizer_name=\"azure_openai_text_3_large\")],\n",
    "        algorithms=[HnswAlgorithmConfiguration(name=\"alg\")],\n",
    "        vectorizers=[\n",
    "            AzureOpenAIVectorizer(\n",
    "                vectorizer_name=\"azure_openai_text_3_large\",\n",
    "                parameters=AzureOpenAIVectorizerParameters(\n",
    "                    resource_url=azure_openai_endpoint,\n",
    "                    deployment_name=azure_openai_embedding_deployment,\n",
    "                    model_name=azure_openai_embedding_model\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    semantic_search=SemanticSearch(\n",
    "        default_configuration_name=\"semantic_config\",\n",
    "        configurations=[\n",
    "            SemanticConfiguration(\n",
    "                name=\"semantic_config\",\n",
    "                prioritized_fields=SemanticPrioritizedFields(\n",
    "                    content_fields=[\n",
    "                        SemanticField(field_name=\"page_chunk\")\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)\n",
    "index_client.create_or_update_index(index)\n",
    "print(f\"Index '{index_name}' created or updated successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39874f61",
   "metadata": {},
   "source": [
    "## Upload sample documents\n",
    "\n",
    "This notebook uses data from NASA's Earth at Night e-book. The data is retrieved from the [azure-search-sample-data](https://github.com/Azure-Samples/azure-search-sample-data) repository on GitHub and passed to the search client for indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded5147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from azure.search.documents import SearchIndexingBufferedSender\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/Azure-Samples/azure-search-sample-data/refs/heads/main/nasa-e-book/earth-at-night-json/documents.json\"\n",
    "documents = requests.get(url).json()\n",
    "\n",
    "with SearchIndexingBufferedSender(endpoint=endpoint, index_name=index_name, credential=credential) as client:\n",
    "    client.upload_documents(documents=documents)\n",
    "\n",
    "print(f\"Documents uploaded to index '{index_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5e0a34",
   "metadata": {},
   "source": [
    "## Create an agent in Azure AI Search\n",
    "\n",
    "This step creates a knowledge agent, which acts as a wrapper for the LLM you deployed to Azure OpenAI. The LLM is used to send queries to an agentic retrieval pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fe4183",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import KnowledgeAgent, KnowledgeAgentAzureOpenAIModel, KnowledgeAgentTargetIndex, KnowledgeAgentRequestLimits, AzureOpenAIVectorizerParameters\n",
    "\n",
    "agent = KnowledgeAgent(\n",
    "    name=agent_name,\n",
    "    models=[\n",
    "        KnowledgeAgentAzureOpenAIModel(\n",
    "            azure_open_ai_parameters=AzureOpenAIVectorizerParameters(\n",
    "                resource_url=azure_openai_endpoint,\n",
    "                deployment_name=azure_openai_gpt_deployment,\n",
    "                model_name=azure_openai_gpt_model\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    "    target_indexes=[\n",
    "        KnowledgeAgentTargetIndex(\n",
    "            index_name=index_name,\n",
    "            default_reranker_threshold=2.5\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "index_client.create_or_update_agent(agent)\n",
    "print(f\"Knowledge agent '{agent_name}' created or updated successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1610cefd",
   "metadata": {},
   "source": [
    "## Set up messages\n",
    "\n",
    "Messages are the input for the retrieval route and contain the conversation history. Each message includes a `role` that indicates its origin, such as `assistant` or `user`, and `content` in natural language. The LLM you use determines which roles are valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ab7b970",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"\n",
    "A Q&A agent that can answer questions about the Earth at night.\n",
    "Sources have a JSON format with a ref_id that must be cited in the answer.\n",
    "If you do not have the answer, respond with \"I don't know\".\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": instructions\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4090707f",
   "metadata": {},
   "source": [
    "## Use agentic retrieval to fetch results\n",
    "\n",
    "This step runs the retrieval pipeline to extract relevant information from your search index. Based on the messages and parameters on the retrieval request, the LLM:\n",
    "\n",
    "1. Analyzes the entire conversation history to determine the underlying information need.\n",
    "\n",
    "1. Breaks down the compound user query into focused subqueries.\n",
    " \n",
    "1. Runs each subquery simultaneously against text fields and vector embeddings in your index.\n",
    "\n",
    "1. Uses semantic ranker to rerank the results of all subqueries.\n",
    "\n",
    "1. Merges the results into a single string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918ded26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.agent import KnowledgeAgentRetrievalClient\n",
    "from azure.search.documents.agent.models import KnowledgeAgentRetrievalRequest, KnowledgeAgentMessage, KnowledgeAgentMessageTextContent, KnowledgeAgentIndexParams\n",
    "\n",
    "print(endpoint)\n",
    "\n",
    "agent_client = KnowledgeAgentRetrievalClient(endpoint=endpoint, agent_name=agent_name, credential=credential)\n",
    "\n",
    "messages.append({\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"\"\"\n",
    "    Why do suburban belts display larger December brightening than urban cores even though absolute light levels are higher downtown?\n",
    "    Why is the Phoenix nighttime street grid is so sharply visible from space, whereas large stretches of the interstate between midwestern cities remain comparatively dim?\n",
    "    \"\"\"\n",
    "})\n",
    "\n",
    "retrieval_result = agent_client.retrieve(\n",
    "    retrieval_request=KnowledgeAgentRetrievalRequest(\n",
    "        messages=[KnowledgeAgentMessage(role=msg[\"role\"], content=[KnowledgeAgentMessageTextContent(text=msg[\"content\"])]) for msg in messages if msg[\"role\"] != \"system\"],\n",
    "        target_index_params=[KnowledgeAgentIndexParams(index_name=index_name, reranker_threshold=2.5)]\n",
    "    )\n",
    ")\n",
    "messages.append({\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": retrieval_result.response[0].content[0].text\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87a035ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.agent import KnowledgeAgentRetrievalClient\n",
    "from azure.search.documents.agent.models import KnowledgeAgentRetrievalRequest, KnowledgeAgentMessage, KnowledgeAgentMessageTextContent, KnowledgeAgentIndexParams\n",
    "\n",
    "agent_client = KnowledgeAgentRetrievalClient(endpoint=endpoint, agent_name=agent_name, credential=credential)\n",
    "\n",
    "messages.append({\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"\"\"\n",
    "    Why do suburban belts display larger December brightening than urban cores even though absolute light levels are higher downtown?\n",
    "    Why is the Phoenix nighttime street grid is so sharply visible from space, whereas large stretches of the interstate between midwestern cities remain comparatively dim?\n",
    "    \"\"\"\n",
    "})\n",
    "\n",
    "retrieval_result = agent_client.retrieve(\n",
    "    retrieval_request=KnowledgeAgentRetrievalRequest(\n",
    "        messages=[KnowledgeAgentMessage(role=msg[\"role\"], content=[KnowledgeAgentMessageTextContent(text=msg[\"content\"])]) for msg in messages if msg[\"role\"] != \"system\"],\n",
    "        target_index_params=[KnowledgeAgentIndexParams(index_name=index_name, reranker_threshold=2.5)]\n",
    "    )\n",
    ")\n",
    "messages.append({\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": retrieval_result.response[0].content[0].text\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18c0e0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.agent import KnowledgeAgentRetrievalClient\n",
    "from azure.search.documents.agent.models import KnowledgeAgentRetrievalRequest, KnowledgeAgentMessage, KnowledgeAgentMessageTextContent, KnowledgeAgentIndexParams\n",
    "\n",
    "agent_client = KnowledgeAgentRetrievalClient(endpoint=endpoint, agent_name=agent_name, credential=credential)\n",
    "\n",
    "messages.append({\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"\"\"\n",
    "    Why do suburban belts display larger December brightening than urban cores even though absolute light levels are higher downtown?\n",
    "    Why is the Phoenix nighttime street grid is so sharply visible from space, whereas large stretches of the interstate between midwestern cities remain comparatively dim?\n",
    "    \"\"\"\n",
    "})\n",
    "\n",
    "retrieval_result = agent_client.retrieve(\n",
    "    retrieval_request=KnowledgeAgentRetrievalRequest(\n",
    "        messages=[KnowledgeAgentMessage(role=msg[\"role\"], content=[KnowledgeAgentMessageTextContent(text=msg[\"content\"])]) for msg in messages if msg[\"role\"] != \"system\"],\n",
    "        target_index_params=[KnowledgeAgentIndexParams(index_name=index_name, reranker_threshold=2.5)]\n",
    "    )\n",
    ")\n",
    "messages.append({\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": retrieval_result.response[0].content[0].text\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886fc687",
   "metadata": {},
   "source": [
    "### Review the retrieval response, activity, and results\n",
    "\n",
    "Each retrieval response from Azure AI Search includes:\n",
    "\n",
    "+ A unified string that represents grounding data from the search results.\n",
    "\n",
    "+ The query plan.\n",
    "\n",
    "+ Reference data that shows which chunks of the source documents contributed to the unified string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d78fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "print(\"Response\")\n",
    "print(textwrap.fill(retrieval_result.response[0].content[0].text, width=120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fccf4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "print(\"Activity\")\n",
    "print(json.dumps([a.as_dict() for a in retrieval_result.activity], indent=2))\n",
    "print(\"Results\")\n",
    "print(json.dumps([r.as_dict() for r in retrieval_result.references], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75386ed1",
   "metadata": {},
   "source": [
    "## Create the Azure OpenAI client\n",
    "\n",
    "So far, this notebook has used agentic retrieval for answer *extraction*, which you can extend to answer *generation* by using the Azure OpenAI client. This enables more detailed, context-rich responses that aren't strictly tied to indexed content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "da260539",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "from azure.identity import get_bearer_token_provider\n",
    "\n",
    "azure_openai_token_provider = get_bearer_token_provider(credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    azure_ad_token_provider=azure_openai_token_provider,\n",
    "    api_version=azure_openai_api_version\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56231e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "answer_model = os.getenv(\"OPENAI_MODEL\", \"gpt-4o\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")  # or \"gpt-4o-mini\"\n",
    "\n",
    "# Create OpenAI client\n",
    "client = OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e200bc2a",
   "metadata": {},
   "source": [
    "### Use the Responses API to generate an answer\n",
    "\n",
    "One option for answer generation is the Responses API, which passes the conversation history to the LLM for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dea5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.responses.create(\n",
    "    model=answer_model,\n",
    "    input=messages\n",
    ")\n",
    "\n",
    "wrapped = textwrap.fill(response.output_text, width=100)\n",
    "print(wrapped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be83f00",
   "metadata": {},
   "source": [
    "Alternatively, you can use the Chat Completions API for answer generation. (with Azure Models that do not support \"Responses\" now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9126b4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_chat_completions = client.chat.completions.create(\n",
    "    model=answer_model,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "wrapped = textwrap.fill(response_chat_completions.choices[0].message.content, width=100)\n",
    "print(wrapped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb96436b",
   "metadata": {},
   "source": [
    "## Continue the conversation\n",
    "\n",
    "This step continues the conversation with the knowledge agent, building upon the previous messages and queries to retrieve relevant information from your search index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7034e480",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append({\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"How do I find lava at night?\"\n",
    "})\n",
    "\n",
    "retrieval_result = agent_client.retrieve(\n",
    "    retrieval_request=KnowledgeAgentRetrievalRequest(\n",
    "        messages=[KnowledgeAgentMessage(role=msg[\"role\"], content=[KnowledgeAgentMessageTextContent(text=msg[\"content\"])]) for msg in messages if msg[\"role\"] != \"system\"],\n",
    "        target_index_params=[KnowledgeAgentIndexParams(index_name=index_name, reranker_threshold=2.5)]\n",
    "    )\n",
    ")\n",
    "messages.append({\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": retrieval_result.response[0].content[0].text\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1cba0c",
   "metadata": {},
   "source": [
    "### Review the retrieval response, activity, and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a1bfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Response\")\n",
    "print(textwrap.fill(retrieval_result.response[0].content[0].text, width=120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f74c2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "print(\"Activity\")\n",
    "print(json.dumps([a.as_dict() for a in retrieval_result.activity], indent=2))\n",
    "print(\"Results\")\n",
    "print(json.dumps([r.as_dict() for r in retrieval_result.references], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7d32cc",
   "metadata": {},
   "source": [
    "## Generate answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6486c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.responses.create(\n",
    "    model=answer_model,\n",
    "    input=messages\n",
    ")\n",
    "\n",
    "wrapped = textwrap.fill(response.output_text, width=100)\n",
    "print(wrapped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75777ed2",
   "metadata": {},
   "source": [
    "## Clean up objects and resources\n",
    "\n",
    "If you no longer need Azure AI Search or Azure OpenAI, delete them from your Azure subscription. You can also start over by deleting individual objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14f6fe6",
   "metadata": {},
   "source": [
    "### Delete the knowledge agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b6a475",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)\n",
    "index_client.delete_agent(agent_name)\n",
    "print(f\"Knowledge agent '{agent_name}' deleted successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35bfbb1",
   "metadata": {},
   "source": [
    "### Delete the search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f5e6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)\n",
    "index_client.delete_index(index)\n",
    "print(f\"Index '{index_name}' deleted successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
